# this model estimates the probability of considering adoption
# and then given the potential for adoption the payment they are willing
# accept for adoption
# N is the total number of survey participants
# M is the total number of survey participants who would consider adoption
# ACCEPT is whether each participant would consider adoption (1 = would consider adoption, 0 = would not consider adoption)
# CENS is a vector of the censoring for each participant who would consider adoption (0 = < 0, 1 = 0 - 2500, 2 = > 2500)
# WTA is $ value of the willingness to accept value for participants who would consider adoption
# with NAs for censored values (i.e., those < 0 and those > 2500) (units = 1000s of $s)
# LIM is censoring interval (in this case it is 0 to 2,500 dollars)
# X is a matrix of covariates for considering adoption
# Nx is the number of covariates for X
# Y is a matrix of covariates for the willingness to accept value
# Ny is the number of covariates for Y
model {
  # likelihood for the probability of considering adoption
  # loop through all survey participants
  for (i in 1:N) {
    ACCEPT[i] ~ dbern(px[i])
    logit(px[i]) <- sum(X[i,] * beta_x) + xsa1[RIDx[i]]
    # model missing data for land value
    X[i, 9] ~ dnorm(mulvx, taulvx)
  }
  # loop through SA1s
  # random effects currently commented out due to lack of replication with SA1 groups
  for (i in 1:NR) {
    #xsa1[i] ~ dnorm(murx[i], taurx)
    #murx[i] <- sum(XR[i,] * betar_x)
    xsa1[i] <- sum(XR[i,] * betar_x)
  }

  # likelihood for willingness to accept values
  # loop through all survey participants who are willing to consider adoption
  for (i in 1:M) {
    CENS[i] ~ dinterval(WTA[i], LIM)
    WTA[i] ~ dnorm(muy[i], tau)
    muy[i] <- sum(Y[i,] * beta_y) + ysa1[RIDy[i]]
    # model missing data for land value
    Y[i, 9] ~ dnorm(mulvy, taulvy)
  }
  # loop through SA1s
  # random effects currently commented out due to lack of replication with SA1 groups
  for (i in 1:MR) {
    #ysa1[i] ~ dnorm(mury[i], taury)
    #mury[i] <- sum(YR[i,] * betar_y)
    ysa1[i] <- sum(YR[i,] * betar_y)
  }

  # likelihood for the proportion of property to apply covenant
  # loop through all survey participants who are willing to consider adoption
  for (i in 1:O) {
    # parameters for beta distribution
    # mean: mu = a / (a + b)
    # precision: phi = a + b
    # hence: a = mu * phi and b = (1 - mu) * phi
    # expectation depends on predictor variables, precision assumed constant
    PROP[i] ~ dbeta(a[i], b[i])
    a[i] <- muz[i] * phi
  	b[i] <- (1 - muz[i]) * phi
    logit(muz[i]) <- sum(Z[i,] * beta_z) + zsa1[RIDz[i]]
    # model missing data for land value
    Z[i, 9] ~ dnorm(mulvz, taulvz)
  }
  # loop through SA1s
  # random effects currently commented out due to lack of replication with SA1 groups
  for (i in 1:OR) {
    #zsa1[i] ~ dnorm(murz[i], taurz)
    #murz[i] <- sum(ZR[i,] * betar_z)
    zsa1[i] <- sum(ZR[i,] * betar_z)
  }

  # Priors
  # uses the approach of Ray-Bing Chen, Chi-Hsiang Chu, Shinsheng Yuan & Ying Nian Wu (2016)
  # Bayesian Sparse Group Selection, Journal of Computational and Graphical Statistics, 25:3,
  # 665-683 for setting priors for variable selection

  # priors for variable inclusion
  p_g <- 0.5
  p_gl <- 0.5

  # individual property level

  # variance components
  tau <- sig^-2
  sig ~ dlnorm(0, 0.001)
  phi ~ dlnorm(0, 0.001)

  # coefficients

  for (i in 1:2) {
    eta_g_temp_x[i] ~ dbern(p_g)
    eta_g_temp_y[i] ~ dbern(p_g)
    eta_g_temp_z[i] ~ dbern(p_g)
  }

  # factor (categorical) variables
  for (i in 1:NxF) {
    eta_g_x[i] <- eta_g_temp_x[FVARX[i]]
    ind_gl_x[i] ~ dbern(p_gl)
    gamma_gl_x[i] <- (1 - eta_g_x[i]) * 0 + (eta_g_x[i] * ind_gl_x[i])
    b_x[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_x[i] <- (1 - (eta_g_x[i] * gamma_gl_x[i])) * 0 + (eta_g_x[i] * gamma_gl_x[i] * b_x[i])
  }
  # continuous variables
  for (i in (NxF + 1):Nx) {
    eta_g_x[i] ~ dbern(p_g)
    b_x[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_x[i] <- (1 - eta_g_x[i]) * 0 + (eta_g_x[i] * b_x[i])
  }
  # factor (categorical) variables
  for (i in 1:NyF) {
    eta_g_y[i] <- eta_g_temp_y[FVARY[i]]
    ind_gl_y[i] ~ dbern(p_gl)
    gamma_gl_y[i] <- (1 - eta_g_y[i]) * 0 + (eta_g_y[i] * ind_gl_y[i])
    b_y[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_y[i] <- (1 - (eta_g_y[i] * gamma_gl_y[i])) * 0 + (eta_g_y[i] * gamma_gl_y[i] * b_y[i])
  }
  # continuous variables
  for (i in (NyF + 1):Ny) {
    eta_g_y[i] ~ dbern(p_g)
    b_y[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_y[i] <- (1 - eta_g_y[i]) * 0 + (eta_g_y[i] * b_y[i])
  }
  # factor (categorical) variables
  for (i in 1:NzF) {
    eta_g_z[i] <- eta_g_temp_z[FVARZ[i]]
    ind_gl_z[i] ~ dbern(p_gl)
    gamma_gl_z[i] <- (1 - eta_g_z[i]) * 0 + (eta_g_z[i] * ind_gl_z[i])
    b_z[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_z[i] <- (1 - (eta_g_z[i] * gamma_gl_z[i])) * 0 + (eta_g_z[i] * gamma_gl_z[i] * b_z[i])
  }
  # continuous variables
  for (i in (NzF + 1):Nz) {
    eta_g_z[i] ~ dbern(p_g)
    b_z[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    beta_z[i] <- (1 - eta_g_z[i]) * 0 + (eta_g_z[i] * b_z[i])
  }

  # SA1 level

  # random effects - currently commented out due to lack of replication with SA1 groups
  #taurx <- sigrx^-2
  #sigrx ~ dlnorm(0, 0.001)
  #taury <- sigry^-2
  #sigry ~ dlnorm(0, 0.001)
  #taurz <- sigrz^-2
  #sigrz ~ dlnorm(0, 0.001)

  # coefficients - currently assumes continuous variables only
  etar_g_x[1] <- 1
  br_x[1] ~ dnorm(0, 0.1)
  betar_x[1] <- br_x[1]
  for (i in 2:NxR) {
    etar_g_x[i] ~ dbern(p_g)
    br_x[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    betar_x[i] <- (1 - etar_g_x[i]) * 0 + etar_g_x[i] * br_x[i]
  }
  etar_g_y[1] <- 1
  br_y[1] ~ dnorm(0, 0.1)
  betar_y[1] <- br_y[1]
  for (i in 2:NyR) {
    etar_g_y[i] ~ dbern(p_g)
    br_y[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    betar_y[i] <- (1 - etar_g_y[i]) * 0 + etar_g_y[i] * br_y[i]
  }
  etar_g_z[1] <- 1
  br_z[1] ~ dnorm(0, 0.1)
  betar_z[1] <- br_z[1]
  for (i in 2:NzR) {
    etar_g_z[i] ~ dbern(p_g)
    br_z[i] ~ dnorm(0, 0.1) # tau fixed but could tune using cross-validation or set inverse-gamma hyperparameter (see Chen et al. 2016)
    betar_z[i] <- (1 - etar_g_z[i]) * 0 + etar_g_z[i] * br_z[i]
  }

  # missing land value data
  taulvx <- siglvx^-2
  siglvx ~ dlnorm(0, 0.001)
  taulvy <- siglvy^-2
  siglvy ~ dlnorm(0, 0.001)
  taulvz <- siglvz^-2
  siglvz ~ dlnorm(0, 0.001)
  mulvx ~ dnorm(0,0.001)
  mulvy ~ dnorm(0,0.001)
  mulvz ~ dnorm(0,0.001)
}
